{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs several models to predict whether posts are from the subreddit r/OCPoetry or r/shortscarystories.\n",
    "The models use different feature sets (word counts, tfidf frequencies, whitespace, sentiment scores, part of speech tagging) and different classification algorithms (logistic regression, naive Bayes, and random forests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and overview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/data_cleaned.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>auth</th>\n",
       "      <th>time</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>new_line_chars</th>\n",
       "      <th>tab_chars</th>\n",
       "      <th>space_chars</th>\n",
       "      <th>zws_chars</th>\n",
       "      <th>title_words</th>\n",
       "      <th>...</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>$</th>\n",
       "      <th>``</th>\n",
       "      <th>#</th>\n",
       "      <th>''</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>subjectivity_abs_dev</th>\n",
       "      <th>polarity_abs_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the moths of time</td>\n",
       "      <td>the moths of time consume your image; everythi...</td>\n",
       "      <td>lizerdqweenchlo</td>\n",
       "      <td>2022-01-26 23:33:47</td>\n",
       "      <td>OCPoetry</td>\n",
       "      <td>0.158273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.029958</td>\n",
       "      <td>0.045054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haunted Houses</td>\n",
       "      <td>Floorboards creak Under little kid feet As a n...</td>\n",
       "      <td>richardcrack</td>\n",
       "      <td>2022-01-26 23:15:39</td>\n",
       "      <td>OCPoetry</td>\n",
       "      <td>0.515723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.795597</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>0.371639</td>\n",
       "      <td>0.115069</td>\n",
       "      <td>0.028366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest of Eden</td>\n",
       "      <td>He could never quite find What made it paradis...</td>\n",
       "      <td>mgmgmgmgm</td>\n",
       "      <td>2022-01-26 22:43:59</td>\n",
       "      <td>OCPoetry</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.013292</td>\n",
       "      <td>0.085332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The deepest fluctuation of creativity</td>\n",
       "      <td>With due regard at your behest I'll smear the ...</td>\n",
       "      <td>puredreadful</td>\n",
       "      <td>2022-01-26 21:53:47</td>\n",
       "      <td>OCPoetry</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.085000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.211708</td>\n",
       "      <td>0.136999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Heart Divided</td>\n",
       "      <td>If I were two instead of just one, I could mak...</td>\n",
       "      <td>robbsmith711</td>\n",
       "      <td>2022-01-26 21:49:32</td>\n",
       "      <td>OCPoetry</td>\n",
       "      <td>0.062130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.970414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256528</td>\n",
       "      <td>0.753272</td>\n",
       "      <td>0.266563</td>\n",
       "      <td>0.204529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "0                      the moths of time   \n",
       "1                         Haunted Houses   \n",
       "2                         Forest of Eden   \n",
       "3  The deepest fluctuation of creativity   \n",
       "4                        A Heart Divided   \n",
       "\n",
       "                                                text             auth  \\\n",
       "0  the moths of time consume your image; everythi...  lizerdqweenchlo   \n",
       "1  Floorboards creak Under little kid feet As a n...     richardcrack   \n",
       "2  He could never quite find What made it paradis...        mgmgmgmgm   \n",
       "3  With due regard at your behest I'll smear the ...     puredreadful   \n",
       "4  If I were two instead of just one, I could mak...     robbsmith711   \n",
       "\n",
       "                 time subreddit  new_line_chars  tab_chars  space_chars  \\\n",
       "0 2022-01-26 23:33:47  OCPoetry        0.158273        0.0     0.964029   \n",
       "1 2022-01-26 23:15:39  OCPoetry        0.515723        0.0     0.795597   \n",
       "2 2022-01-26 22:43:59  OCPoetry        0.560000        0.0     0.920000   \n",
       "3 2022-01-26 21:53:47  OCPoetry        0.390244        0.0     0.829268   \n",
       "4 2022-01-26 21:49:32  OCPoetry        0.062130        0.0     0.970414   \n",
       "\n",
       "   zws_chars  title_words  ...    (    )    $   ``    #   ''  polarity  \\\n",
       "0   0.000000            4  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.006944   \n",
       "1   0.053459            2  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.023633   \n",
       "2   0.066667            3  ...  0.0  0.0  0.0  0.0  0.0  0.0 -0.033333   \n",
       "3   0.024390            5  ...  0.0  0.0  0.0  0.0  0.0  0.0 -0.085000   \n",
       "4   0.000000            3  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.256528   \n",
       "\n",
       "   subjectivity  subjectivity_abs_dev  polarity_abs_dev  \n",
       "0      0.516667              0.029958          0.045054  \n",
       "1      0.371639              0.115069          0.028366  \n",
       "2      0.500000              0.013292          0.085332  \n",
       "3      0.275000              0.211708          0.136999  \n",
       "4      0.753272              0.266563          0.204529  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56550 entries, 0 to 56549\n",
      "Data columns (total 62 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   title                 56550 non-null  object        \n",
      " 1   text                  56550 non-null  object        \n",
      " 2   auth                  56550 non-null  object        \n",
      " 3   time                  56550 non-null  datetime64[ns]\n",
      " 4   subreddit             56550 non-null  object        \n",
      " 5   new_line_chars        56550 non-null  float64       \n",
      " 6   tab_chars             56550 non-null  float64       \n",
      " 7   space_chars           56550 non-null  float64       \n",
      " 8   zws_chars             56550 non-null  float64       \n",
      " 9   title_words           56550 non-null  int64         \n",
      " 10  text_words            56550 non-null  int64         \n",
      " 11  word_count            56550 non-null  int64         \n",
      " 12  title_text            56550 non-null  object        \n",
      " 13  CC                    56550 non-null  float64       \n",
      " 14  CD                    56550 non-null  float64       \n",
      " 15  DT                    56550 non-null  float64       \n",
      " 16  EX                    56550 non-null  float64       \n",
      " 17  FW                    56550 non-null  float64       \n",
      " 18  IN                    56550 non-null  float64       \n",
      " 19  JJ                    56550 non-null  float64       \n",
      " 20  JJR                   56550 non-null  float64       \n",
      " 21  JJS                   56550 non-null  float64       \n",
      " 22  LS                    56550 non-null  float64       \n",
      " 23  MD                    56550 non-null  float64       \n",
      " 24  NN                    56550 non-null  float64       \n",
      " 25  NNS                   56550 non-null  float64       \n",
      " 26  NNP                   56550 non-null  float64       \n",
      " 27  NNPS                  56550 non-null  float64       \n",
      " 28  PDT                   56550 non-null  float64       \n",
      " 29  POS                   56550 non-null  float64       \n",
      " 30  PRP                   56550 non-null  float64       \n",
      " 31  PRP$                  56550 non-null  float64       \n",
      " 32  RB                    56550 non-null  float64       \n",
      " 33  RBR                   56550 non-null  float64       \n",
      " 34  RBS                   56550 non-null  float64       \n",
      " 35  RP                    56550 non-null  float64       \n",
      " 36  SYM                   56550 non-null  float64       \n",
      " 37  TO                    56550 non-null  float64       \n",
      " 38  UH                    56550 non-null  float64       \n",
      " 39  VB                    56550 non-null  float64       \n",
      " 40  VBD                   56550 non-null  float64       \n",
      " 41  VBG                   56550 non-null  float64       \n",
      " 42  VBN                   56550 non-null  float64       \n",
      " 43  VBP                   56550 non-null  float64       \n",
      " 44  VBZ                   56550 non-null  float64       \n",
      " 45  WDT                   56550 non-null  float64       \n",
      " 46  WP                    56550 non-null  float64       \n",
      " 47  WP$                   56550 non-null  float64       \n",
      " 48  WRB                   56550 non-null  float64       \n",
      " 49  .                     56550 non-null  float64       \n",
      " 50  ,                     56550 non-null  float64       \n",
      " 51  :                     56550 non-null  float64       \n",
      " 52  (                     56550 non-null  float64       \n",
      " 53  )                     56550 non-null  float64       \n",
      " 54  $                     56550 non-null  float64       \n",
      " 55  ``                    56550 non-null  float64       \n",
      " 56  #                     56550 non-null  float64       \n",
      " 57  ''                    56550 non-null  float64       \n",
      " 58  polarity              56550 non-null  float64       \n",
      " 59  subjectivity          56550 non-null  float64       \n",
      " 60  subjectivity_abs_dev  56550 non-null  float64       \n",
      " 61  polarity_abs_dev      56550 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(53), int64(3), object(5)\n",
      "memory usage: 26.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text and title columns have a few NAs but that is okay since we will only use the merged `title_text` column as a feature which does not have NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isna().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is balanced. For balanced datasets accuracy is a reasonable metric and a baseline model scores about 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCPoetry             0.50603\n",
       "shortscarystories    0.49397\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['subreddit']\n",
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text only models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train, test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title_text']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, X_train = X_train, X_test = X_test, y_train = y_train, y_test = y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Training score: {model.score(X_train, y_train):.3f}\")\n",
    "    print(f\"Testing score: {model.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature ranking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top_features(feature_series):\n",
    "    print(\"=== Top features for OCPoetry ===\")\n",
    "    print(feature_series.sort_values().head(10))\n",
    "    print()\n",
    "    print(\"=== Top features for shortscarystories ===\")\n",
    "    print(feature_series.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_coefs_lr(lr_model):\n",
    "    lr_coefs = lr_model.coef_\n",
    "    features = lr_model.feature_names_in_\n",
    "    lr_coefs_series = pd.Series(lr_coefs[0], index = features)\n",
    "\n",
    "    display_top_features(lr_coefs_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_coefs_lr_pipe(lr_pipe):\n",
    "    lr_coefs = lr_pipe.named_steps['logisticregression'].coef_\n",
    "    features = lr_pipe.named_steps['tfidfvectorizer'].get_feature_names_out()\n",
    "    lr_coefs_series = pd.Series(lr_coefs[0], index = features)\n",
    "\n",
    "    display_top_features(lr_coefs_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "* Text features only\n",
    "* Tfidf vectorizer\n",
    "* logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a MaxAbsScaler is used because it works well with sparse out put from the Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(\n",
    "    TfidfVectorizer(max_features = 1000),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(max_iter = 10_000, solver = 'saga', warm_start = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model scores 91.3% accuracy on the training set and is overfitting by about 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.924\n",
      "Testing score: 0.913\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "feedback   -12.037625\n",
      "poem       -11.312260\n",
      "poetry      -6.673354\n",
      "heart       -4.331140\n",
      "wrote       -3.551745\n",
      "in          -3.479486\n",
      "like        -2.992899\n",
      "yet         -2.909161\n",
      "lines       -2.731072\n",
      "love        -2.675275\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "horror         5.127167\n",
      "story          3.994172\n",
      "stories        3.663051\n",
      "was            3.444374\n",
      "immediately    3.310995\n",
      "police         3.261500\n",
      "basement       3.191972\n",
      "it             3.125241\n",
      "killed         3.055125\n",
      "people         2.973666\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr_pipe(pipe1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LogisticRegressionCV model takes about 6-7 times longer to run. Since they don't give significantly different answers for C > 1, I will leave it at the default value (c = 1) for most models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.928\n",
      "Testing score: 0.913\n"
     ]
    }
   ],
   "source": [
    "pipe1_cv = make_pipeline(\n",
    "    TfidfVectorizer(max_features = 1000),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegressionCV(max_iter = 10_000, solver  = 'saga')\n",
    ")\n",
    "run_model(pipe1_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([166.81005372])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1_cv.named_steps['logisticregressioncv'].C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-04, 7.74263683e-04, 5.99484250e-03, 4.64158883e-02,\n",
       "       3.59381366e-01, 2.78255940e+00, 2.15443469e+01, 1.66810054e+02,\n",
       "       1.29154967e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1_cv.named_steps['logisticregressioncv'].Cs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81586703, 0.85028881, 0.87091831, 0.90086054, 0.9217258 ,\n",
       "        0.92455499, 0.92679477, 0.92644112, 0.9258517 , 0.9258517 ],\n",
       "       [0.80938347, 0.83626076, 0.85677237, 0.88753979, 0.90746198,\n",
       "        0.91264883, 0.91253094, 0.91241306, 0.91241306, 0.91241306],\n",
       "       [0.80464513, 0.8382457 , 0.86135345, 0.89177081, 0.90980901,\n",
       "        0.91275643, 0.91346381, 0.91405329, 0.9138175 , 0.9138175 ],\n",
       "       [0.81714218, 0.8416647 , 0.8632398 , 0.89636878, 0.91546805,\n",
       "        0.91853336, 0.9171186 , 0.9173544 , 0.9172365 , 0.9173544 ],\n",
       "       [0.80995048, 0.83718463, 0.85934921, 0.89294978, 0.91075218,\n",
       "        0.91322801, 0.91216694, 0.91228484, 0.91240274, 0.91240274]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1_cv.named_steps['logisticregressioncv'].scores_['shortscarystories']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - Logistic regression with stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should add some stop words that might make this task too easy by giving away the answer directly: poem / poetry, feedback, story and stories.\n",
    "Note that the word 'feedback' is present overwhelmingly in r/OCPoetry because of a rule that each submission include links to 2 of the author's comments giving feedback to other posts.\n",
    "These links are often put in a section labeled feedback, for example like this https://www.reddit.com/r/OCPoetry/comments/sevmm6/tell_daisy/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['poem', 'poems', 'ocpoetry', 'poet', 'poets', 'poetry', 'link', 'links', 'feedback', 'story', 'stories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(\n",
    "    TfidfVectorizer(max_features = 1000, stop_words=stop_words),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(max_iter = 10_000, solver = 'saga', warm_start = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the previous model, taking out stop words reduced the model accuracy by about 0.5% on both the test and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.917\n",
      "Testing score: 0.907\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "wrote    -4.920941\n",
      "heart    -4.531349\n",
      "in       -3.481216\n",
      "yet      -3.144788\n",
      "lines    -3.010759\n",
      "like     -2.966011\n",
      "love     -2.821241\n",
      "write    -2.705977\n",
      "tears    -2.621535\n",
      "beauty   -2.606099\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "horror         6.734071\n",
      "was            3.567471\n",
      "short          3.509582\n",
      "immediately    3.453581\n",
      "police         3.380810\n",
      "basement       3.241785\n",
      "killed         3.088144\n",
      "it             3.070294\n",
      "people         3.054826\n",
      "normal         3.045111\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr_pipe(pipe2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = make_pipeline(\n",
    "    TfidfVectorizer(max_features = 1000, stop_words=stop_words),\n",
    "    MaxAbsScaler(),\n",
    "    MultinomialNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.855\n",
      "Testing score: 0.856\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ranks the importance of features in a Naive Bayes model by taking the difference of the log-odds of feature appearing in one sub reddit versus the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_features_nb(nb_pipe):\n",
    "    nb_log_odds = nb_pipe.named_steps['multinomialnb'].feature_log_prob_\n",
    "    features = nb_pipe.named_steps['tfidfvectorizer'].get_feature_names_out()\n",
    "    classes = nb_pipe.named_steps['multinomialnb'].classes_\n",
    "    nb_log_odds_df = pd.DataFrame(nb_log_odds.T, index = features, columns = classes)\n",
    "\n",
    "    # print(nb_log_odds_df.head())\n",
    "    log_odds_diff = nb_log_odds_df['OCPoetry'] - nb_log_odds_df['shortscarystories']\n",
    "    print(\"=== Top features for OCPoetry ===\")\n",
    "    print(log_odds_diff.sort_values(ascending = False).head(10))\n",
    "    print()\n",
    "    print(\"=== Top features for shortscarystories ===\")\n",
    "    print(log_odds_diff.sort_values().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "lies      1.993306\n",
      "beauty    1.991780\n",
      "dance     1.825713\n",
      "amp       1.816486\n",
      "sea       1.754919\n",
      "wrote     1.659528\n",
      "fly       1.635383\n",
      "lines     1.628444\n",
      "stars     1.597872\n",
      "love      1.585213\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "immediately   -2.649222\n",
      "grabbed       -2.526056\n",
      "police        -2.236366\n",
      "hallway       -2.174541\n",
      "basement      -2.100894\n",
      "screamed      -2.054198\n",
      "mommy         -1.992400\n",
      "mr            -1.965775\n",
      "noticed       -1.910459\n",
      "continued     -1.863802\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_features_nb(pipe3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes model is picking up an additional words that should be removed: amp. I'm not sure exactly what this is but it is used in formatting primarily for r/OCPoetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.append('amp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rerun models with full stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_4 = make_pipeline(\n",
    "    TfidfVectorizer(max_features = 1000, stop_words=stop_words),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(max_iter = 10_000, solver = 'saga', warm_start = True)\n",
    ")\n",
    "\n",
    "pipe_mnb_4 = make_pipeline(\n",
    "    TfidfVectorizer(max_features = 1000, stop_words=stop_words),\n",
    "    MaxAbsScaler(),\n",
    "    MultinomialNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.916\n",
      "Testing score: 0.908\n",
      "=== Top features for OCPoetry ===\n",
      "wrote    -4.921162\n",
      "heart    -4.562286\n",
      "in       -3.506538\n",
      "yet      -3.125402\n",
      "lines    -3.101091\n",
      "like     -2.972417\n",
      "love     -2.816242\n",
      "write    -2.720307\n",
      "tears    -2.645069\n",
      "beauty   -2.631192\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "horror         6.741139\n",
      "was            3.580709\n",
      "short          3.506101\n",
      "immediately    3.443394\n",
      "police         3.408741\n",
      "basement       3.256193\n",
      "killed         3.099632\n",
      "people         3.080351\n",
      "it             3.079355\n",
      "normal         3.064435\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe_lr_4)\n",
    "top_coefs_lr_pipe(pipe_lr_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.854\n",
      "Testing score: 0.856\n",
      "=== Top features for OCPoetry ===\n",
      "lies       1.993838\n",
      "beauty     1.989419\n",
      "dance      1.826234\n",
      "sea        1.756161\n",
      "wrote      1.659703\n",
      "fly        1.637861\n",
      "lines      1.629195\n",
      "stars      1.598677\n",
      "flowers    1.586283\n",
      "love       1.585677\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "immediately   -2.642404\n",
      "grabbed       -2.526920\n",
      "police        -2.236521\n",
      "hallway       -2.167739\n",
      "basement      -2.095728\n",
      "screamed      -2.054749\n",
      "mommy         -1.992926\n",
      "mr            -1.964524\n",
      "noticed       -1.911430\n",
      "continued     -1.864214\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe_mnb_4)\n",
    "top_features_nb(pipe_mnb_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some overlap in the top features for the two models but many major differences: for instance the word \"was\" is the #1 feature for the logistic regression model for the shortscarystories class but not in the top 10 for the naive-Bayes model. Note that I won't compare the magnitudes of scores (only the rankings) between the two models because they represent different quantites (coefficients for the logistic regression model vs log-probabilities for the naive-Bayes model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf_5 = make_pipeline(\n",
    "    TfidfVectorizer(max_features = 1000, stop_words = stop_words),\n",
    "    RandomForestClassifier(min_samples_split=40)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest models are significantly slower to train than either naive-Bayes or logistic regression and they are extremely overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.980\n",
      "Testing score: 0.871\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe_rf_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since randomized forest models overfit the dataset I tried an Extra Trees classifier but this didn't help much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_et_6 = make_pipeline(\n",
    "    TfidfVectorizer(max_features = 1000, stop_words = stop_words),\n",
    "    ExtraTreesClassifier(min_samples_split=40, n_jobs = -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.996\n",
      "Testing score: 0.879\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe_et_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_et_7 = make_pipeline(\n",
    "    TfidfVectorizer(max_features = 1000, stop_words = stop_words),\n",
    "    ExtraTreesClassifier(min_samples_split=100, n_jobs = -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.972\n",
      "Testing score: 0.874\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe_et_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Larger Tfidf vector\n",
    "As expected increasing the max_features parameter increases the accuracy. \n",
    "The logistic regression accuracy improved from 0.908 to 0.923 and the naive bayes model accuracy improved from 0.856 to 0.891."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_7 = make_pipeline(\n",
    "    TfidfVectorizer(max_features = 5000, stop_words=stop_words),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(max_iter = 10_000, solver = 'saga', warm_start = True)\n",
    ")\n",
    "\n",
    "pipe_mnb_7 = make_pipeline(\n",
    "    TfidfVectorizer(max_features = 5000, stop_words=stop_words),\n",
    "    MaxAbsScaler(),\n",
    "    MultinomialNB()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.950\n",
      "Testing score: 0.923\n",
      "=== Top features for OCPoetry ===\n",
      "wrote         -3.646506\n",
      "heart         -3.396637\n",
      "comment       -2.671619\n",
      "appreciated   -2.609973\n",
      "write         -2.579816\n",
      "lost          -2.508521\n",
      "like          -2.500696\n",
      "by            -2.493230\n",
      "context       -2.483748\n",
      "yet           -2.435211\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "horror       4.632961\n",
      "scary        4.156407\n",
      "people       2.981689\n",
      "short        2.975123\n",
      "was          2.965614\n",
      "halloween    2.941921\n",
      "creepy       2.911811\n",
      "horrible     2.861187\n",
      "000          2.782803\n",
      "blood        2.759967\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe_lr_7)\n",
    "top_coefs_lr_pipe(pipe_lr_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.889\n",
      "Testing score: 0.891\n",
      "=== Top features for OCPoetry ===\n",
      "haiku        4.023383\n",
      "sonnet       3.836621\n",
      "critique     3.265102\n",
      "ode          3.240962\n",
      "strife       3.024006\n",
      "verse        2.781688\n",
      "dew          2.768746\n",
      "criticism    2.623925\n",
      "rhymes       2.586109\n",
      "bloom        2.579035\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "250           -2.924117\n",
      "sprinted      -2.814273\n",
      "downstairs    -2.806918\n",
      "shrugged      -2.784462\n",
      "911           -2.751644\n",
      "freaked       -2.708616\n",
      "detective     -2.692527\n",
      "officer       -2.682599\n",
      "immediately   -2.680528\n",
      "nodded        -2.623328\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe_mnb_7)\n",
    "top_features_nb(pipe_mnb_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_8 = make_pipeline(\n",
    "    CountVectorizer(max_features = 1000, stop_words=stop_words),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(max_iter = 10_000, solver = 'saga', warm_start = True)\n",
    ")\n",
    "\n",
    "pipe_mnb_8 = make_pipeline(\n",
    "    CountVectorizer(max_features = 1000, stop_words=stop_words),\n",
    "    MaxAbsScaler(),\n",
    "    MultinomialNB()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the tfidf vectorizer the logistic regression performed worse (0.901 vs 0.908) and the naive Bayes model did slightly better (0.857 vs 0.856)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.910\n",
      "Testing score: 0.901\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe_lr_8)\n",
    "# top_coefs_lr_pipe(pipe_lr_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.854\n",
      "Testing score: 0.857\n"
     ]
    }
   ],
   "source": [
    "run_model(pipe_mnb_8)\n",
    "# top_features_nb(pipe_mnb_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparing feature sets I will stick with logistic regression models as they are fast to train and one of the most accuracte models in the previous section. Additionally, I will use no penalty term as these are small feature sets and overfitting is not a concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'text', 'auth', 'time', 'subreddit', 'new_line_chars',\n",
       "       'tab_chars', 'space_chars', 'zws_chars', 'title_words', 'text_words',\n",
       "       'word_count', 'title_text', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ',\n",
       "       'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PDT', 'POS',\n",
       "       'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD',\n",
       "       'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '.', ',', ':',\n",
       "       '(', ')', '$', '``', '#', '''', 'polarity', 'subjectivity',\n",
       "       'subjectivity_abs_dev', 'polarity_abs_dev'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['title', 'text', 'auth', 'time', 'subreddit'])\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White space features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.908\n",
      "Testing score: 0.910\n"
     ]
    }
   ],
   "source": [
    "X_ws = X[['new_line_chars', 'tab_chars', 'space_chars', 'zws_chars']]\n",
    "X_ws_train, X_ws_test, y_train, y_test = train_test_split(X_ws, y)\n",
    "\n",
    "ws_model = LogisticRegression(solver = 'saga', max_iter=1_000, penalty='none')\n",
    "run_model(ws_model, X_ws_train, X_ws_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model trained on average white space alone is incredibly powerful at 90.9% accuracy, nearly identical to the tfidf vectorization model score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "new_line_chars   -21.005176\n",
      "space_chars       -3.706502\n",
      "tab_chars         -0.034591\n",
      "zws_chars          1.131805\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "zws_chars          1.131805\n",
      "tab_chars         -0.034591\n",
      "space_chars       -3.706502\n",
      "new_line_chars   -21.005176\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr(ws_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line break characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the power in the white space model came from new line characters - which alone achieved 90% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.903\n",
      "Testing score: 0.902\n"
     ]
    }
   ],
   "source": [
    "X_lb = X[['new_line_chars']]\n",
    "X_lb_train, X_lb_test, y_train, y_test = train_test_split(X_lb, y)\n",
    "\n",
    "lb_model = LogisticRegression(solver = 'saga', max_iter = 1_000, penalty='none')\n",
    "run_model(lb_model, X_lb_train, X_lb_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-20.01077195]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parts of speech words only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "      <th>LS</th>\n",
       "      <th>...</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.048951</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046921</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.102639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105572</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.041056</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.008798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CC        CD        DT        EX   FW        IN        JJ       JJR  \\\n",
       "0  0.034965  0.000000  0.090909  0.013986  0.0  0.139860  0.069930  0.000000   \n",
       "1  0.037500  0.006250  0.121875  0.003125  0.0  0.078125  0.096875  0.000000   \n",
       "2  0.064103  0.000000  0.141026  0.000000  0.0  0.089744  0.012821  0.000000   \n",
       "3  0.086957  0.000000  0.130435  0.000000  0.0  0.108696  0.086957  0.000000   \n",
       "4  0.046921  0.032258  0.102639  0.000000  0.0  0.105572  0.052786  0.005865   \n",
       "\n",
       "        JJS   LS  ...        VB       VBD       VBG       VBN       VBP  \\\n",
       "0  0.000000  0.0  ...  0.034965  0.020979  0.027972  0.006993  0.006993   \n",
       "1  0.000000  0.0  ...  0.065625  0.034375  0.006250  0.031250  0.028125   \n",
       "2  0.000000  0.0  ...  0.038462  0.076923  0.012821  0.025641  0.012821   \n",
       "3  0.043478  0.0  ...  0.065217  0.021739  0.000000  0.021739  0.000000   \n",
       "4  0.002933  0.0  ...  0.052786  0.023460  0.011730  0.032258  0.041056   \n",
       "\n",
       "        VBZ       WDT        WP       WP$       WRB  \n",
       "0  0.048951  0.020979  0.000000  0.000000  0.020979  \n",
       "1  0.021875  0.000000  0.003125  0.000000  0.009375  \n",
       "2  0.051282  0.012821  0.012821  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.032258  0.005865  0.008798  0.002933  0.008798  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pos_words = X.loc[:, 'CC':'WRB']\n",
    "X_pos_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using parts of speech for the words alone gives more than 75% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.781\n",
      "Testing score: 0.776\n"
     ]
    }
   ],
   "source": [
    "X_pos_words_train, X_pos_words_test, y_train, y_test = train_test_split(X_pos_words, y)\n",
    "pos_words_model = LogisticRegression(solver = 'saga', max_iter=10000, penalty='none')\n",
    "run_model(pos_words_model, X_pos_words_train, X_pos_words_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parts of speech most indicative of r/OCPoetry are\n",
    "* WP$ - wh-pronoun, possessive\n",
    "* PDT - predeterminer\n",
    "* WDT - wh-determiner\n",
    "* NNPS - Noun, proper plural\n",
    "* FW - foreign word\n",
    "* WRB - wh-adverbs\n",
    "* VBP - verb, non-third person singular present\n",
    "\n",
    "The coefficients for the top features indicative of r/shortscarystories are much larger in magnitude. These are\n",
    "* UH - interjection\n",
    "* RBS - adverb superlative\n",
    "* RP - adverb particle\n",
    "* VBD - verb, past tense\n",
    "* CD - cardinal number\n",
    "\n",
    "The full set of codes with examples are available [here](https://ericthornton.net/NLP-3/ref_nlp_penn_treebank2_pos_tags_list.php)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "WP$    -37.404944\n",
      "PDT    -33.253315\n",
      "FW     -13.774780\n",
      "NNPS   -12.441442\n",
      "WDT    -11.931092\n",
      "WRB     -3.324410\n",
      "NNS      0.236422\n",
      "VBP      0.265308\n",
      "NN       0.295517\n",
      "NNP      1.071429\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "UH     60.480832\n",
      "RP     45.102590\n",
      "RBS    44.988755\n",
      "VBD    33.622909\n",
      "SYM    32.746047\n",
      "CD     28.022512\n",
      "DT     22.471586\n",
      "EX     22.126166\n",
      "JJS    18.995177\n",
      "VBG    18.667828\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr(pos_words_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parts of speech words and punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think some of the punctuation (for example semicolons) might be part of the display formatting in addition to the post content so take these scores with a grain of salt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "      <th>LS</th>\n",
       "      <th>...</th>\n",
       "      <th>WRB</th>\n",
       "      <th>.</th>\n",
       "      <th>,</th>\n",
       "      <th>:</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>$</th>\n",
       "      <th>``</th>\n",
       "      <th>#</th>\n",
       "      <th>''</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046921</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.102639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105572</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.049853</td>\n",
       "      <td>0.041056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CC        CD        DT        EX   FW        IN        JJ       JJR  \\\n",
       "0  0.034965  0.000000  0.090909  0.013986  0.0  0.139860  0.069930  0.000000   \n",
       "1  0.037500  0.006250  0.121875  0.003125  0.0  0.078125  0.096875  0.000000   \n",
       "2  0.064103  0.000000  0.141026  0.000000  0.0  0.089744  0.012821  0.000000   \n",
       "3  0.086957  0.000000  0.130435  0.000000  0.0  0.108696  0.086957  0.000000   \n",
       "4  0.046921  0.032258  0.102639  0.000000  0.0  0.105572  0.052786  0.005865   \n",
       "\n",
       "        JJS   LS  ...       WRB         .         ,         :    (    )    $  \\\n",
       "0  0.000000  0.0  ...  0.020979  0.069930  0.034965  0.013986  0.0  0.0  0.0   \n",
       "1  0.000000  0.0  ...  0.009375  0.012500  0.078125  0.000000  0.0  0.0  0.0   \n",
       "2  0.000000  0.0  ...  0.000000  0.064103  0.089744  0.012821  0.0  0.0  0.0   \n",
       "3  0.043478  0.0  ...  0.000000  0.021739  0.043478  0.000000  0.0  0.0  0.0   \n",
       "4  0.002933  0.0  ...  0.008798  0.049853  0.041056  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "    ``    #   ''  \n",
       "0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pos = X.loc[:, 'CC':\"''\"]\n",
    "X_pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When punctuation is added the model accuracy increases to 82.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.825\n",
      "Testing score: 0.830\n"
     ]
    }
   ],
   "source": [
    "X_pos_train, X_pos_test, y_train, y_test = train_test_split(X_pos, y)\n",
    "pos_model = LogisticRegression(solver = 'saga', max_iter=10000, penalty = 'none')\n",
    "run_model(pos_model, X_pos_train, X_pos_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punctuation that is indicative of r/OCPoetry are colons, parentheses, and commas while '.' (any sentence ending punctuation including semicolon, question mark and asterik) is indicative of r/shortscarystories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "PDT    -26.603900\n",
      ")      -18.595669\n",
      "WP$    -11.921533\n",
      "(      -11.602885\n",
      ":      -10.210653\n",
      "NNPS    -7.122741\n",
      "WDT     -4.090550\n",
      ",       -3.404712\n",
      "NNS     -2.294215\n",
      "WP      -1.869267\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "SYM    61.189710\n",
      "RBS    48.406086\n",
      "RP     43.596306\n",
      "VBD    32.634892\n",
      "CD     28.396462\n",
      ".      23.363808\n",
      "TO     23.349770\n",
      "''     21.804615\n",
      "UH     21.685121\n",
      "JJS    20.142304\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr(pos_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>subjectivity_abs_dev</th>\n",
       "      <th>polarity_abs_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.029958</td>\n",
       "      <td>0.045054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023633</td>\n",
       "      <td>0.371639</td>\n",
       "      <td>0.115069</td>\n",
       "      <td>0.028366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.013292</td>\n",
       "      <td>0.085332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.085000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.211708</td>\n",
       "      <td>0.136999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.256528</td>\n",
       "      <td>0.753272</td>\n",
       "      <td>0.266563</td>\n",
       "      <td>0.204529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity  subjectivity  subjectivity_abs_dev  polarity_abs_dev\n",
       "0  0.006944      0.516667              0.029958          0.045054\n",
       "1  0.023633      0.371639              0.115069          0.028366\n",
       "2 -0.033333      0.500000              0.013292          0.085332\n",
       "3 -0.085000      0.275000              0.211708          0.136999\n",
       "4  0.256528      0.753272              0.266563          0.204529"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sentiment = X.loc[:, 'polarity':]\n",
    "X_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.638\n",
      "Testing score: 0.643\n"
     ]
    }
   ],
   "source": [
    "X_sentiment_train, X_sentiment_test, y_train, y_test = train_test_split(X_sentiment, y)\n",
    "sentiment_model = LogisticRegression(solver = 'saga', penalty = 'none', max_iter = 1000)\n",
    "run_model(sentiment_model, X_sentiment_train, X_sentiment_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected in the feature engineering notebook, higher absolute deviation scores for subjectivity and polarity are both decent predictors of r/OCPoetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "subjectivity_abs_dev   -4.939392\n",
      "polarity_abs_dev       -3.593634\n",
      "polarity               -1.665226\n",
      "subjectivity           -1.052128\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "subjectivity           -1.052128\n",
      "polarity               -1.665226\n",
      "polarity_abs_dev       -3.593634\n",
      "subjectivity_abs_dev   -4.939392\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr(sentiment_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_len = X[['title_words', 'text_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.673\n",
      "Testing score: 0.678\n"
     ]
    }
   ],
   "source": [
    "X_len_train, X_len_test, y_train, y_test = train_test_split(X_len, y)\n",
    "len_model = LogisticRegression(solver = 'saga', penalty = 'none', max_iter = 1000)\n",
    "run_model(len_model, X_len_train, X_len_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "title_words   -0.125606\n",
      "text_words     0.004062\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "text_words     0.004062\n",
      "title_words   -0.125606\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr(len_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text + Other Feature models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['new_line_chars', 'tab_chars', 'space_chars', 'zws_chars',\n",
       "       'title_words', 'text_words', 'word_count', 'title_text', 'CC', 'CD',\n",
       "       'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS',\n",
       "       'NNP', 'NNPS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP',\n",
       "       'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP',\n",
       "       'WP$', 'WRB', '.', ',', ':', '(', ')', '$', '``', '#', '''', 'polarity',\n",
       "       'subjectivity', 'subjectivity_abs_dev', 'polarity_abs_dev'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords relisted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poem',\n",
       " 'poems',\n",
       " 'ocpoetry',\n",
       " 'poet',\n",
       " 'poets',\n",
       " 'poetry',\n",
       " 'link',\n",
       " 'links',\n",
       " 'feedback',\n",
       " 'story',\n",
       " 'stories',\n",
       " 'amp']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [\n",
    "    'poem',\n",
    "    'poems',\n",
    "    'ocpoetry',\n",
    "    'poet',\n",
    "    'poets',\n",
    "    'poetry',\n",
    "    'link',\n",
    "    'links',\n",
    "    'feedback',\n",
    "    'story',\n",
    "    'stories',\n",
    "    'amp'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get top features from a pipeline with a column transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_coefs_lr_pipe_ct(lr_pipe):\n",
    "    lr_coefs = lr_pipe.named_steps['logisticregression'].coef_\n",
    "    features = lr_pipe.named_steps['columntransformer'].get_feature_names_out()\n",
    "    lr_coefs_series = pd.Series(lr_coefs[0], index = features)\n",
    "\n",
    "    display_top_features(lr_coefs_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier our logistic regression model with the full set of stop words and 1000 max features scored 90.5% accuracy. Let's see if adding the other features improves the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text + white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_ws = X[['title_text', 'new_line_chars', 'tab_chars', 'space_chars', 'zws_chars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.950\n",
      "Testing score: 0.942\n"
     ]
    }
   ],
   "source": [
    "X_text_ws_train, X_text_ws_test, y_train, y_test = train_test_split(X_text_ws, y)\n",
    "\n",
    "tfidf_ws_model = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=1000, stop_words = stop_words), 'title_text'),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(solver = 'saga', max_iter = 10_000)\n",
    ")\n",
    "\n",
    "run_model(tfidf_ws_model, X_text_ws_train, X_text_ws_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the model accuracy has increased to 94.4% (4% above text alone).\n",
    "New line characters are now the most important feature for the r/OCPoetry class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "new_line_chars   -40.666970\n",
      "in                -3.827819\n",
      "wrote             -3.715967\n",
      "heart             -3.607654\n",
      "space_chars       -3.197771\n",
      "on                -2.789489\n",
      "tears             -2.771591\n",
      "like              -2.559365\n",
      "lost              -2.501376\n",
      "thoughts          -2.491645\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "horror         5.390850\n",
      "immediately    3.368985\n",
      "police         3.171657\n",
      "woods          3.086173\n",
      "creature       2.889418\n",
      "10             2.871255\n",
      "basement       2.757289\n",
      "humans         2.692898\n",
      "it             2.627196\n",
      "going          2.497763\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr_pipe_ct(tfidf_ws_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text + Parts of speech words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_text</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "      <th>...</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the moths of timethe moths of time consume you...</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.048951</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haunted HousesFloorboards creak Under little k...</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest of EdenHe could never quite find What m...</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The deepest fluctuation of creativityWith due ...</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Heart DividedIf I were two instead of just o...</td>\n",
       "      <td>0.046921</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.102639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105572</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.041056</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.008798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_text        CC        CD  \\\n",
       "0  the moths of timethe moths of time consume you...  0.034965  0.000000   \n",
       "1  Haunted HousesFloorboards creak Under little k...  0.037500  0.006250   \n",
       "2  Forest of EdenHe could never quite find What m...  0.064103  0.000000   \n",
       "3  The deepest fluctuation of creativityWith due ...  0.086957  0.000000   \n",
       "4  A Heart DividedIf I were two instead of just o...  0.046921  0.032258   \n",
       "\n",
       "         DT        EX   FW        IN        JJ       JJR       JJS  ...  \\\n",
       "0  0.090909  0.013986  0.0  0.139860  0.069930  0.000000  0.000000  ...   \n",
       "1  0.121875  0.003125  0.0  0.078125  0.096875  0.000000  0.000000  ...   \n",
       "2  0.141026  0.000000  0.0  0.089744  0.012821  0.000000  0.000000  ...   \n",
       "3  0.130435  0.000000  0.0  0.108696  0.086957  0.000000  0.043478  ...   \n",
       "4  0.102639  0.000000  0.0  0.105572  0.052786  0.005865  0.002933  ...   \n",
       "\n",
       "         VB       VBD       VBG       VBN       VBP       VBZ       WDT  \\\n",
       "0  0.034965  0.020979  0.027972  0.006993  0.006993  0.048951  0.020979   \n",
       "1  0.065625  0.034375  0.006250  0.031250  0.028125  0.021875  0.000000   \n",
       "2  0.038462  0.076923  0.012821  0.025641  0.012821  0.051282  0.012821   \n",
       "3  0.065217  0.021739  0.000000  0.021739  0.000000  0.000000  0.000000   \n",
       "4  0.052786  0.023460  0.011730  0.032258  0.041056  0.032258  0.005865   \n",
       "\n",
       "         WP       WP$       WRB  \n",
       "0  0.000000  0.000000  0.020979  \n",
       "1  0.003125  0.000000  0.009375  \n",
       "2  0.012821  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  \n",
       "4  0.008798  0.002933  0.008798  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_pos_words = pd.merge(X[['title_text']], X.loc[:, 'CC': 'WRB'], left_index=True, right_index=True)\n",
    "X_text_pos_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.919\n",
      "Testing score: 0.913\n"
     ]
    }
   ],
   "source": [
    "X_text_pos_words_train, X_text_pos_words_test, y_train, y_test = train_test_split(X_text_pos_words, y)\n",
    "\n",
    "tfidf_pos_words_model = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=1000, stop_words = stop_words), 'title_text'),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(solver = 'saga', max_iter = 10_000)\n",
    ")\n",
    "\n",
    "run_model(tfidf_pos_words_model, X_text_pos_words_train, X_text_pos_words_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding parts of speech didn't improve the accuracy scores much, although the model is a bit more overfit.\n",
    "One new feature (CD for cardinal numbers) is a top predictor for the r/shortscarystories class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "wrote    -5.250292\n",
      "heart    -4.091023\n",
      "yet      -3.040635\n",
      "in       -2.867425\n",
      "tears    -2.829278\n",
      "beauty   -2.772554\n",
      "too      -2.644396\n",
      "self     -2.598258\n",
      "hold     -2.572093\n",
      "how      -2.517427\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "horror         6.855577\n",
      "CD             4.177349\n",
      "people         3.776545\n",
      "woods          3.706782\n",
      "short          3.474840\n",
      "immediately    3.448027\n",
      "police         3.329630\n",
      "the            3.174981\n",
      "blood          3.164818\n",
      "basement       3.100818\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr_pipe_ct(tfidf_pos_words_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text + Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_text</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "      <th>...</th>\n",
       "      <th>WRB</th>\n",
       "      <th>.</th>\n",
       "      <th>,</th>\n",
       "      <th>:</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>$</th>\n",
       "      <th>``</th>\n",
       "      <th>#</th>\n",
       "      <th>''</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the moths of timethe moths of time consume you...</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haunted HousesFloorboards creak Under little k...</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest of EdenHe could never quite find What m...</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The deepest fluctuation of creativityWith due ...</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Heart DividedIf I were two instead of just o...</td>\n",
       "      <td>0.046921</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.102639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105572</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.049853</td>\n",
       "      <td>0.041056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_text        CC        CD  \\\n",
       "0  the moths of timethe moths of time consume you...  0.034965  0.000000   \n",
       "1  Haunted HousesFloorboards creak Under little k...  0.037500  0.006250   \n",
       "2  Forest of EdenHe could never quite find What m...  0.064103  0.000000   \n",
       "3  The deepest fluctuation of creativityWith due ...  0.086957  0.000000   \n",
       "4  A Heart DividedIf I were two instead of just o...  0.046921  0.032258   \n",
       "\n",
       "         DT        EX   FW        IN        JJ       JJR       JJS  ...  \\\n",
       "0  0.090909  0.013986  0.0  0.139860  0.069930  0.000000  0.000000  ...   \n",
       "1  0.121875  0.003125  0.0  0.078125  0.096875  0.000000  0.000000  ...   \n",
       "2  0.141026  0.000000  0.0  0.089744  0.012821  0.000000  0.000000  ...   \n",
       "3  0.130435  0.000000  0.0  0.108696  0.086957  0.000000  0.043478  ...   \n",
       "4  0.102639  0.000000  0.0  0.105572  0.052786  0.005865  0.002933  ...   \n",
       "\n",
       "        WRB         .         ,         :    (    )    $   ``    #   ''  \n",
       "0  0.020979  0.069930  0.034965  0.013986  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.009375  0.012500  0.078125  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.000000  0.064103  0.089744  0.012821  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.000000  0.021739  0.043478  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.008798  0.049853  0.041056  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_pos = pd.merge(X[['title_text']], X.loc[:, 'CC': \"''\"], left_index=True, right_index=True)\n",
    "X_text_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.926\n",
      "Testing score: 0.919\n"
     ]
    }
   ],
   "source": [
    "X_text_pos_train, X_text_pos_test, y_train, y_test = train_test_split(X_text_pos, y)\n",
    "\n",
    "tfidf_pos_model = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=1000, stop_words = stop_words), 'title_text'),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(solver = 'saga', max_iter = 10_000)\n",
    ")\n",
    "\n",
    "run_model(tfidf_pos_model, X_text_pos_train, X_text_pos_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding puctuation improved the accuracy to 91.9%, 1% better than text features alone.\n",
    "Several punctuation categories are considered important predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "wrote      -3.934112\n",
      ":          -3.311919\n",
      "yet        -3.209056\n",
      "heart      -3.058565\n",
      "too        -2.961161\n",
      "NN         -2.861498\n",
      "hold       -2.806737\n",
      "thoughts   -2.779332\n",
      "how        -2.740932\n",
      "sun        -2.675523\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      ".              12.297766\n",
      "horror          7.249787\n",
      "police          3.524063\n",
      "immediately     3.481813\n",
      "blood           3.393138\n",
      "people          3.322424\n",
      "short           3.267682\n",
      "CD              3.203260\n",
      "kill            2.955705\n",
      "anyone          2.929604\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr_pipe_ct(tfidf_pos_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text + Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_text</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity_abs_dev</th>\n",
       "      <th>polarity_abs_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the moths of timethe moths of time consume you...</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.029958</td>\n",
       "      <td>0.045054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haunted HousesFloorboards creak Under little k...</td>\n",
       "      <td>0.371639</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>0.115069</td>\n",
       "      <td>0.028366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest of EdenHe could never quite find What m...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.013292</td>\n",
       "      <td>0.085332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The deepest fluctuation of creativityWith due ...</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>-0.085000</td>\n",
       "      <td>0.211708</td>\n",
       "      <td>0.136999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Heart DividedIf I were two instead of just o...</td>\n",
       "      <td>0.753272</td>\n",
       "      <td>0.256528</td>\n",
       "      <td>0.266563</td>\n",
       "      <td>0.204529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_text  subjectivity  polarity  \\\n",
       "0  the moths of timethe moths of time consume you...      0.516667  0.006944   \n",
       "1  Haunted HousesFloorboards creak Under little k...      0.371639  0.023633   \n",
       "2  Forest of EdenHe could never quite find What m...      0.500000 -0.033333   \n",
       "3  The deepest fluctuation of creativityWith due ...      0.275000 -0.085000   \n",
       "4  A Heart DividedIf I were two instead of just o...      0.753272  0.256528   \n",
       "\n",
       "   subjectivity_abs_dev  polarity_abs_dev  \n",
       "0              0.029958          0.045054  \n",
       "1              0.115069          0.028366  \n",
       "2              0.013292          0.085332  \n",
       "3              0.211708          0.136999  \n",
       "4              0.266563          0.204529  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_sentiment = X[['title_text', 'subjectivity', 'polarity', 'subjectivity_abs_dev', 'polarity_abs_dev']]\n",
    "X_text_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.917\n",
      "Testing score: 0.910\n"
     ]
    }
   ],
   "source": [
    "X_text_sentiment_train, X_text_sentiment_test, y_train, y_test = train_test_split(X_text_sentiment, y)\n",
    "\n",
    "tfidf_sentiment_model = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=1000, stop_words = stop_words), 'title_text'),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(solver = 'saga', max_iter = 10_000)\n",
    ")\n",
    "\n",
    "run_model(tfidf_sentiment_model, X_text_sentiment_train, X_text_sentiment_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding sentiment scores did not improve the model at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "heart    -4.272049\n",
      "wrote    -4.157044\n",
      "in       -3.619239\n",
      "lines    -3.029128\n",
      "yet      -2.922951\n",
      "write    -2.909054\n",
      "hold     -2.795991\n",
      "beauty   -2.772525\n",
      "like     -2.632382\n",
      "broken   -2.624433\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "horror         6.960576\n",
      "immediately    3.920164\n",
      "was            3.827585\n",
      "short          3.383369\n",
      "police         3.323896\n",
      "people         3.235936\n",
      "creature       3.066061\n",
      "mommy          3.054932\n",
      "basement       3.030434\n",
      "however        3.006283\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr_pipe_ct(tfidf_sentiment_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text + Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_text</th>\n",
       "      <th>text_words</th>\n",
       "      <th>title_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the moths of timethe moths of time consume you...</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haunted HousesFloorboards creak Under little k...</td>\n",
       "      <td>317</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest of EdenHe could never quite find What m...</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The deepest fluctuation of creativityWith due ...</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Heart DividedIf I were two instead of just o...</td>\n",
       "      <td>337</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_text  text_words  title_words\n",
       "0  the moths of timethe moths of time consume you...         138            4\n",
       "1  Haunted HousesFloorboards creak Under little k...         317            2\n",
       "2  Forest of EdenHe could never quite find What m...          74            3\n",
       "3  The deepest fluctuation of creativityWith due ...          40            5\n",
       "4  A Heart DividedIf I were two instead of just o...         337            3"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_len = X[['title_text', 'text_words', 'title_words']]\n",
    "X_text_len.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.919\n",
      "Testing score: 0.909\n"
     ]
    }
   ],
   "source": [
    "X_text_len_train, X_text_len_test, y_train, y_test = train_test_split(X_text_len, y)\n",
    "\n",
    "tfidf_len_model = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=1000, stop_words = stop_words), 'title_text'),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(solver = 'saga', max_iter = 10_000)\n",
    ")\n",
    "\n",
    "run_model(tfidf_len_model, X_text_len_train, X_text_len_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding word lengths also did not improve the model much, even though text_words was a top feature for r/shortscarystories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "wrote      -4.793735\n",
      "heart      -4.129321\n",
      "in         -4.095815\n",
      "yet        -3.223627\n",
      "like       -3.015009\n",
      "lies       -2.978029\n",
      "beauty     -2.944950\n",
      "thoughts   -2.764993\n",
      "tears      -2.760192\n",
      "on         -2.684196\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      "text_words     8.492802\n",
      "horror         6.593044\n",
      "immediately    3.837194\n",
      "police         3.773925\n",
      "was            3.513856\n",
      "people         3.066337\n",
      "short          3.047620\n",
      "however        2.995588\n",
      "humans         2.995524\n",
      "mommy          2.961199\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr_pipe_ct(tfidf_len_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_train, X_all_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.953\n",
      "Testing score: 0.948\n"
     ]
    }
   ],
   "source": [
    "tfidf_all_features_model = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=1000, stop_words = stop_words), 'title_text'),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(solver = 'saga', max_iter = 10_000)\n",
    ")\n",
    "\n",
    "run_model(tfidf_all_features_model, X_all_train, X_all_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "new_line_chars   -39.192570\n",
      "wrote             -3.825403\n",
      "heart             -3.410960\n",
      "space_chars       -2.868872\n",
      "too               -2.695912\n",
      "yet               -2.691979\n",
      "tears             -2.551375\n",
      "in                -2.528592\n",
      "lost              -2.366558\n",
      "write             -2.311113\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      ".              11.404029\n",
      "horror          5.604725\n",
      "word_count      3.839304\n",
      "text_words      3.830713\n",
      "immediately     3.354428\n",
      "woods           2.887923\n",
      "people          2.874973\n",
      "police          2.837151\n",
      "short           2.816935\n",
      "human           2.679333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr_pipe_ct(tfidf_all_features_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.971\n",
      "Testing score: 0.954\n"
     ]
    }
   ],
   "source": [
    "tfidf_all_features_model_2 = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=5000, stop_words = stop_words), 'title_text'),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(solver = 'saga', max_iter = 10_000)\n",
    ")\n",
    "\n",
    "run_model(tfidf_all_features_model_2, X_all_train, X_all_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.950\n",
      "Testing score: 0.945\n"
     ]
    }
   ],
   "source": [
    "tfidf_all_features_model_3 = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=1000, ngram_range=(1, 2), stop_words = stop_words), 'title_text'),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegression(solver = 'saga', max_iter = 10_000)\n",
    ")\n",
    "\n",
    "run_model(tfidf_all_features_model_3, X_all_train, X_all_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top features for OCPoetry ===\n",
      "new_line_chars   -39.881668\n",
      "write             -3.067242\n",
      "space_chars       -3.037629\n",
      "too               -2.829226\n",
      "yet               -2.704275\n",
      "heart             -2.655500\n",
      "hold              -2.500517\n",
      "tears             -2.401326\n",
      "lost              -2.235802\n",
      "broken            -2.223843\n",
      "dtype: float64\n",
      "\n",
      "=== Top features for shortscarystories ===\n",
      ".             11.585344\n",
      "word_count     3.474441\n",
      "text_words     3.467284\n",
      "human          3.213541\n",
      "short          3.095649\n",
      "body           3.044933\n",
      "people         2.945535\n",
      "killed         2.922256\n",
      "police         2.863864\n",
      "happened       2.760034\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_coefs_lr_pipe_ct(tfidf_all_features_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - this cell may take > 1 hour to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.976\n",
      "Testing score: 0.953\n"
     ]
    }
   ],
   "source": [
    "tfidf_all_features_model_4 = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words = stop_words), 'title_text'),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    LogisticRegressionCV(Cs = 24, solver = 'saga', max_iter = 10_000)\n",
    ")\n",
    "\n",
    "# run_model(tfidf_all_features_model_4, X_all_train, X_all_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.49249555])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_all_features_model_4.named_steps['logisticregressioncv'].C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.873\n",
      "Testing score: 0.870\n"
     ]
    }
   ],
   "source": [
    "tfidf_all_features_model_mnb = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words = stop_words), 'title_text'),\n",
    "        ('drop', ['subjectivity', 'polarity']),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "run_model(tfidf_all_features_model_mnb, X_all_train, X_all_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2447           15.96m\n",
      "         2           1.1291           23.43m\n",
      "         3           1.0311           17.40m\n",
      "         4           0.9487           14.33m\n",
      "         5           0.8790           12.50m\n",
      "         6           0.8183           14.21m\n",
      "         7           0.7657           12.93m\n",
      "         8           0.7209           11.88m\n",
      "         9           0.6814           11.07m\n",
      "        10           0.6465           12.02m\n",
      "        11           0.6159           12.74m\n",
      "        12           0.5892           11.99m\n",
      "        13           0.5645           11.35m\n",
      "        14           0.5428           11.77m\n",
      "        15           0.5244           11.39m\n",
      "        16           0.5072           10.87m\n",
      "        17           0.4917           10.41m\n",
      "        18           0.4780           10.09m\n",
      "        19           0.4652           11.00m\n",
      "        20           0.4532           10.78m\n",
      "        21           0.4434           10.37m\n",
      "        22           0.4333           10.11m\n",
      "        23           0.4248           10.33m\n",
      "        24           0.4168            9.96m\n",
      "        25           0.4088            9.62m\n",
      "        26           0.4020            9.30m\n",
      "        27           0.3959            9.48m\n",
      "        28           0.3901            9.63m\n",
      "        29           0.3847            9.31m\n",
      "        30           0.3796            9.02m\n",
      "        31           0.3746            8.73m\n",
      "        32           0.3694            8.57m\n",
      "        33           0.3655            8.60m\n",
      "        34           0.3618            8.34m\n",
      "        35           0.3583            8.09m\n",
      "        36           0.3551            7.86m\n",
      "        37           0.3518            7.64m\n",
      "        38           0.3488            7.60m\n",
      "        39           0.3457            7.53m\n",
      "        40           0.3426            7.31m\n",
      "        41           0.3399            7.11m\n",
      "        42           0.3375            7.13m\n",
      "        43           0.3354            6.97m\n",
      "        44           0.3329            7.03m\n",
      "        45           0.3309            6.83m\n",
      "        46           0.3287            6.63m\n",
      "        47           0.3265            6.63m\n",
      "        48           0.3244            6.47m\n",
      "        49           0.3225            6.29m\n",
      "        50           0.3207            6.10m\n",
      "        51           0.3190            6.04m\n",
      "        52           0.3172            5.92m\n",
      "        53           0.3155            5.74m\n",
      "        54           0.3135            5.69m\n",
      "        55           0.3119            5.56m\n",
      "        56           0.3104            5.38m\n",
      "        57           0.3090            5.33m\n",
      "        58           0.3073            5.20m\n",
      "        59           0.3060            5.03m\n",
      "        60           0.3046            4.98m\n",
      "        61           0.3031            4.83m\n",
      "        62           0.3017            4.67m\n",
      "        63           0.3002            4.51m\n",
      "        64           0.2988            4.46m\n",
      "        65           0.2974            4.30m\n",
      "        66           0.2960            4.15m\n",
      "        67           0.2945            4.00m\n",
      "        68           0.2933            3.92m\n",
      "        69           0.2915            3.79m\n",
      "        70           0.2903            3.65m\n",
      "        71           0.2890            3.50m\n",
      "        72           0.2880            3.43m\n",
      "        73           0.2869            3.29m\n",
      "        74           0.2856            3.22m\n",
      "        75           0.2845            3.08m\n",
      "        76           0.2834            2.94m\n",
      "        77           0.2824            2.81m\n",
      "        78           0.2813            2.71m\n",
      "        79           0.2802            2.58m\n",
      "        80           0.2791            2.44m\n",
      "        81           0.2780            2.31m\n",
      "        82           0.2773            2.17m\n",
      "        83           0.2765            2.04m\n",
      "        84           0.2754            1.91m\n",
      "        85           0.2745            1.78m\n",
      "        86           0.2736            1.66m\n",
      "        87           0.2727            1.53m\n",
      "        88           0.2719            1.40m\n",
      "        89           0.2709            1.28m\n",
      "        90           0.2701            1.16m\n",
      "        91           0.2692            1.04m\n",
      "        92           0.2681           56.73s\n",
      "        93           0.2670           49.56s\n",
      "        94           0.2662           43.13s\n",
      "        95           0.2653           35.82s\n",
      "        96           0.2643           28.96s\n",
      "        97           0.2634           21.61s\n",
      "        98           0.2627           14.34s\n",
      "        99           0.2618            7.24s\n",
      "       100           0.2610            0.00s\n",
      "Training score: 0.953\n",
      "Testing score: 0.948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "tfidf_all_features_model_grad = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words = stop_words), 'title_text'),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    GradientBoostingClassifier(verbose = 2)\n",
    ")\n",
    "\n",
    "run_model(tfidf_all_features_model_grad, X_all_train, X_all_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 96.0% accuracy, lightGBM is the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21047, number of negative: 21365\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.155511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1004157\n",
      "[LightGBM] [Info] Number of data points in the train set: 42412, number of used features: 5055\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496251 -> initscore=-0.014996\n",
      "[LightGBM] [Info] Start training from score -0.014996\n",
      "Training score: 0.979\n",
      "Testing score: 0.960\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "tfidf_all_features_model_lgbm = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words = stop_words), 'title_text'),\n",
    "        remainder = 'passthrough',\n",
    "        verbose_feature_names_out = False\n",
    "    ),\n",
    "    MaxAbsScaler(),\n",
    "    lgb.LGBMClassifier(verbosity = 1)\n",
    ")\n",
    "\n",
    "run_model(tfidf_all_features_model_lgbm, X_all_train, X_all_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_line_chars    205\n",
       ".                 143\n",
       "space_chars       129\n",
       "VBD                71\n",
       "text_words         63\n",
       "zws_chars          55\n",
       "word_count         43\n",
       "NNP                40\n",
       "love               37\n",
       "of                 29\n",
       "Name: feature importance, dtype: int32"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(\n",
    "    tfidf_all_features_model_lgbm.named_steps['lgbmclassifier'].feature_importances_,\n",
    "    index = tfidf_all_features_model_lgbm.named_steps['columntransformer'].get_feature_names_out(),\n",
    "    name = 'feature importance'\n",
    ").sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x19c2bcede80>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(tfidf_all_features_model_lgbm, X_all_test, y_test, cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine misclassified poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_best = tfidf_all_features_model_lgbm.predict(X_all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45495</th>\n",
       "      <td>if you can read thisit means you have the virus and I am sorry for spilling out to you like this through online. It's just that I don't want to be infected.</td>\n",
       "      <td>shortscarystories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25028</th>\n",
       "      <td>I Hate DogsYou can listen to me perform my [spoken poem --- I was really, really hurt by a dog when I was younger. And now, whenever I spend time around a dog, I get scared that maybe they're goin...</td>\n",
       "      <td>OCPoetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47856</th>\n",
       "      <td>The Most Foul Thing Of AllYou think your life is good. Itâ€™s mostly devoid of threats, save for some hardships here and there, but nothing too big. You think youâ€™re safe. But youâ€™re not, because I ...</td>\n",
       "      <td>shortscarystories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28546</th>\n",
       "      <td>Dad, will you read my sonnet? Oh...I tried to write a sonnet about Dad. Do you know how hard they are to create? Iambic what? I swear that I went mad. To count these syllables filled me with hate....</td>\n",
       "      <td>OCPoetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26229</th>\n",
       "      <td>I was convinced I was going to burn the house down todayI was convinced I was going to burn the house down today. The hob wouldn't turn off and I was there alone. I was convinced something would c...</td>\n",
       "      <td>OCPoetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12183</th>\n",
       "      <td>Delay Your Son a MinuteIf you like this Poem, please leave an upvote and some feedback to satisfy my instant gratification. Thank you. Enjoy! Give us a minute. So we can come together. Hide his lu...</td>\n",
       "      <td>OCPoetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55821</th>\n",
       "      <td>Don't call me, I'll call youYeah it's me. Dude, do you know what time it is? Do you know this isn't an appropriate time to be calling me? I'm tired of you calling me like this. I don't care that y...</td>\n",
       "      <td>shortscarystories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38272</th>\n",
       "      <td>Sometimes love can be the death of you...ðŸ”ªEnjoy these creepy tinder date stories gone wrong and **subscribe** for consistent nightmares ðŸ‘«âš°ï¸ðŸŽƒ</td>\n",
       "      <td>shortscarystories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15165</th>\n",
       "      <td>UntitledDarkness has always been a part of my life. I guess thatâ€™s why I find comfort here. I let my demons seduce me. No longer fighting against the current. Relaxing now because, struggling only...</td>\n",
       "      <td>OCPoetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16842</th>\n",
       "      <td>Kingdom comeThe babe in wrap through her tattered vale was the sole glee on the causeway of dread. The knight's eyes turned wary with every trot His ringmail in hack, when a sword had run red. A t...</td>\n",
       "      <td>OCPoetry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    title_text  \\\n",
       "45495                                             if you can read thisit means you have the virus and I am sorry for spilling out to you like this through online. It's just that I don't want to be infected.   \n",
       "25028  I Hate DogsYou can listen to me perform my [spoken poem --- I was really, really hurt by a dog when I was younger. And now, whenever I spend time around a dog, I get scared that maybe they're goin...   \n",
       "47856  The Most Foul Thing Of AllYou think your life is good. Itâ€™s mostly devoid of threats, save for some hardships here and there, but nothing too big. You think youâ€™re safe. But youâ€™re not, because I ...   \n",
       "28546  Dad, will you read my sonnet? Oh...I tried to write a sonnet about Dad. Do you know how hard they are to create? Iambic what? I swear that I went mad. To count these syllables filled me with hate....   \n",
       "26229  I was convinced I was going to burn the house down todayI was convinced I was going to burn the house down today. The hob wouldn't turn off and I was there alone. I was convinced something would c...   \n",
       "12183  Delay Your Son a MinuteIf you like this Poem, please leave an upvote and some feedback to satisfy my instant gratification. Thank you. Enjoy! Give us a minute. So we can come together. Hide his lu...   \n",
       "55821  Don't call me, I'll call youYeah it's me. Dude, do you know what time it is? Do you know this isn't an appropriate time to be calling me? I'm tired of you calling me like this. I don't care that y...   \n",
       "38272                                                             Sometimes love can be the death of you...ðŸ”ªEnjoy these creepy tinder date stories gone wrong and **subscribe** for consistent nightmares ðŸ‘«âš°ï¸ðŸŽƒ   \n",
       "15165  UntitledDarkness has always been a part of my life. I guess thatâ€™s why I find comfort here. I let my demons seduce me. No longer fighting against the current. Relaxing now because, struggling only...   \n",
       "16842  Kingdom comeThe babe in wrap through her tattered vale was the sole glee on the causeway of dread. The knight's eyes turned wary with every trot His ringmail in hack, when a sword had run red. A t...   \n",
       "\n",
       "               subreddit  \n",
       "45495  shortscarystories  \n",
       "25028           OCPoetry  \n",
       "47856  shortscarystories  \n",
       "28546           OCPoetry  \n",
       "26229           OCPoetry  \n",
       "12183           OCPoetry  \n",
       "55821  shortscarystories  \n",
       "38272  shortscarystories  \n",
       "15165           OCPoetry  \n",
       "16842           OCPoetry  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong_preds = preds_best != y_test\n",
    "with pd.option_context('max_colwidth', 200):\n",
    "    display(X_all_test[wrong_preds].join(y_test)[['title_text', 'subreddit']].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9212599b6527739aacc5bcb356ff64f10af8be4731f2141d8d60dd08601fabb0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
